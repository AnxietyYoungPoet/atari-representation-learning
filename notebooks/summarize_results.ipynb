{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/evanracah/Dropbox/projects/rl-representation-learning/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.atari_ram_annotations import summary_key_dict, atari_dict, unused_keys, detailed_key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dicts_in_dict(dic):\n",
    "    rems = []\n",
    "    for k,v in dic.items():\n",
    "        if isinstance(v,dict) or isinstance(v,list):\n",
    "            rems.append(k)\n",
    "    for k in rems:            \n",
    "        if isinstance(dic[k], list):\n",
    "            for i,v in enumerate(dic[k]):\n",
    "                dic[k+\"_\"+str(i)] = v\n",
    "        dic.pop(k)\n",
    "        \n",
    "    return dic\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts_for(method, verbose=True):\n",
    "    rem_games = [\"defender\",\"enduro\"]\n",
    "    api = wandb.Api()\n",
    "    if method in [\"random_cnn\",\"supervised\",\"majority\"]:\n",
    "        runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": method,\n",
    "                                                 \"config.collect_mode\":\"random_agent\",\n",
    "                                                \"config.probe_steps\": 50000,\n",
    "                                                #\"config.entropy_threshold\":0.3,\n",
    "                                                 \"state\": \"finished\"}))\n",
    "    else:\n",
    "        runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": method,\n",
    "                                                         \"config.collect_mode\":\"random_agent\",\n",
    "                                                         \"config.train_encoder\":True,\n",
    "                                                       \"config.feature_size\":256,\n",
    "                                                         \"config.probe_steps\": 50000,\n",
    "                                                         \"config.entropy_threshold\":0.3,\n",
    "                                                         \"state\": \"finished\", \n",
    "                                                        #\"config.patience\":10\n",
    "                                                        }))\n",
    "\n",
    "\n",
    "\n",
    "    runs_info = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\") + \"_\" + run.name :remove_dicts_in_dict(run.config) for run in runs}\n",
    "    summary_metrics = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\") + \"_\" + run.name :run.summary_metrics for run in runs }\n",
    "    summary_metrics = {k:v for k,v in summary_metrics.items() if k.split(\"_\")[0].lower() not in rem_games}\n",
    "    run_summary_dict = {name:{} for name in summary_metrics.keys()}\n",
    "    for run_name, run in summary_metrics.items():\n",
    "        for summary_name, key_list in summary_key_dict.items():\n",
    "            run_mean_values = {k.lower():v for k,v in run.items() if \"mean\" in k and \"var\" not in k  and  any(sum_key.lower() in k.lower() for sum_key in key_list)}\n",
    "            #print(run_mean_values)\n",
    "            #run_stderr_values = {k:v for k,v in run.items() if \"stderr\" in k and \"mean\" not in k and any(sum_key in k.lower() for sum_key in key_list)}\n",
    "            if len(run_mean_values) > 0:\n",
    "                run_summary = np.mean(list(run_mean_values.values()))\n",
    "                #overall_summary_dict[summary_name].append(run_summary)\n",
    "                run_summary_dict[run_name][summary_name] = run_summary\n",
    "                #print(\"\\t\",summary_name,run_summary_dict[run_name][summary_name])\n",
    "        run_summary_dict[run_name][\"overall\"] = np.mean(list(run_summary_dict[run_name].values()))\n",
    "                \n",
    "    for game_name in atari_dict.keys():\n",
    "        duplicates = [run_name for run_name in summary_metrics.keys() if game_name in run_name.lower()]\n",
    "        num_duplicates = len(duplicates)\n",
    "        if num_duplicates > 1:\n",
    "            \n",
    "            duplicates_info = {run_name: runs_info[run_name] for run_name in duplicates}\n",
    "            if verbose:\n",
    "                print(\"Game {} is in summary {} times as:\".format(game_name, num_duplicates))\n",
    "                print(\"\\t\",duplicates)\n",
    "                print(\"\\tDifferences are: \")\n",
    "                for rn in list(duplicates_info.keys())[1:]:\n",
    "                    rn1 = list(duplicates_info.keys())[0]\n",
    "                    dup1 = duplicates_info[rn1]\n",
    "                    dupi = duplicates_info[rn]\n",
    "                    print(\"\\t\\t run {} differs with run {}\".format(rn1,rn),set(dup1.items()).symmetric_difference(set(dupi.items())))\n",
    "            duplicates_time_stamps = [summary_metrics[run_name][\"_timestamp\"] for run_name in duplicates ]\n",
    "            most_recent_index = np.argmax(duplicates_time_stamps)\n",
    "            \n",
    "            for i, run_name in enumerate(duplicates):\n",
    "                if i != most_recent_index:\n",
    "                    run_summary_dict.pop(run_name)\n",
    "    run_keys = list(run_summary_dict.keys()) # make list ahead of time cuz we are changing the dictionary inside the loop\n",
    "    for run_name in run_keys:\n",
    "        run_dict = deepcopy(run_summary_dict[run_name])\n",
    "        run_summary_dict.pop(run_name)\n",
    "        game_name = run_name.split(\"_\")[0]\n",
    "        run_summary_dict[game_name] = run_dict\n",
    "            \n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "    return run_summary_dict, runs_info, summary_metrics, runs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_summary_dict(run_summary_dict):\n",
    "    all_dups = []\n",
    "    for game_name in atari_dict.keys():       \n",
    "        duplicates = [run_name for run_name in run_summary_dict.keys() if game_name in run_name.lower()]\n",
    "        all_dups.append(duplicates)\n",
    "        num_duplicates = len(duplicates)\n",
    "        if num_duplicates > 1:\n",
    "            print(\"You still have duplicates!\".format(game_name, num_duplicates))\n",
    "            print(\"\\t\",duplicates)\n",
    "            print(\"\")\n",
    "            \n",
    "    overall_summary_dict = {k:[] for k in list(summary_key_dict.keys()) + [\"overall\"]}\n",
    "    for run_name, key_dict in run_summary_dict.items():\n",
    "        for key,value in key_dict.items():\n",
    "            overall_summary_dict[key].append(value)\n",
    "        \n",
    "    overall_summary_dict = {k:np.mean(v) for k,v in overall_summary_dict.items()}\n",
    "\n",
    "\n",
    "    return overall_summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_summary_dict,runs_info, summary_metrics, runs = get_dicts_for(\"naff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_overall_summary_dict(run_summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"majority\",\"random-cnn\", \"naff\",\"vae\",\"appo\",\"cpc\",\"spatial-appo\",\"supervised\"]\n",
    "gbg_dict = {env:{} for env in atari_dict.keys()}\n",
    "overall_dict = {method:{} for method in methods}\n",
    "\n",
    "for method in methods:\n",
    "    run_summary_dict, _, _, _ = get_dicts_for(method, verbose=False)\n",
    "    overall_summary_dict = compute_overall_summary_dict(run_summary_dict)\n",
    "    for env, dic in run_summary_dict.items():\n",
    "        if len(dic) > 0:\n",
    "            gbg_dict[env.lower()][method] = dic[\"overall\"]\n",
    "        else:\n",
    "            gbg_dict[env.lower()][method] = \"n/a\"\n",
    "    overall_dict[method] = overall_summary_dict[\"overall\"]\n",
    "\n",
    "print(\" & \".join([\"game\"] + methods), \"\\\\\\\\\")\n",
    "\n",
    "for game, dic in gbg_dict.items():\n",
    "    if game in [\"videopinball\", \"asteroids\"]:\n",
    "        continue\n",
    "    print(\" & \".join([game] + [\"%8.2f\"%(100*dic[k]) if k in dic else \"n/a\" for k in methods ]), \"\\\\\\\\\")\n",
    "\n",
    "\n",
    "print(\" & \".join([\"overall\"] + [\"%8.2f\"%(100*overall_dict[k]) if k in overall_dict else \"n/a\" for k in methods ]), \"\\\\\\\\\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(summary_key_dict.keys())\n",
    "print(\" & \".join(keys))\n",
    "for method in methods:\n",
    "    run_summary_dict,runs_info, summary_metrics, runs = get_dicts_for(method, verbose=False)\n",
    "    overall_summary_dict = compute_overall_summary_dict(run_summary_dict)\n",
    "\n",
    "    nums = [\"%8.2f\"%(100*overall_summary_dict[k]) if k in overall_summary_dict else \"n/a\" for k in keys]\n",
    "    print(method + \" & \",\" & \".join(nums), \"\\\\\\\\\")\n",
    "\n",
    "# print(\" & \".join(misc_keys))    \n",
    "# for method in methods:\n",
    "#     overall_summary_dict, run_summary_dict, _ = get_dicts_for(method)\n",
    "\n",
    "\n",
    "\n",
    "#     misc_nums = [\"%8.2f\"%(100*overall_summary_dict[k]) for k in misc_keys]\n",
    "#     print(method + \" & \",\" & \".join(misc_nums), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(detailed_key_dict.keys())\n",
    "summary_stats = {env:{sk:0 for sk in keys} for env in atari_dict.keys()}\n",
    "\n",
    "for env in atari_dict.keys():\n",
    "    for k in atari_dict[env].keys():\n",
    "        for sk,v in detailed_key_dict.items():\n",
    "            if k in v:\n",
    "                summary_stats[env][sk] +=1\n",
    "\n",
    "print(\" & \".join([\"game\"] + list(keys)))\n",
    "\n",
    "for env,v in summary_stats.items():\n",
    "    print( \" & \".join([env] + list(str(v[k]) for k in keys)), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_rl_dicts(algo):\n",
    "    api = wandb.Api()\n",
    "    runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": \"pretrained-rl-agent\",\n",
    "                                                     \"config.zoo_algos\":[algo],\n",
    "                                                     \"config.probe_collect_mode\":\"atari_zoo\",\n",
    "                                                     \"state\": \"finished\"}))\n",
    "\n",
    "    runs = [run for run in runs if \"test_mean_reward_per_episode\" in run.summary_metrics.keys()]\n",
    "\n",
    "    run_info_dict = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\")  :run.config for run in runs}\n",
    "    run_dict = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\")  :run.summary_metrics for run in runs}\n",
    "\n",
    "    run_summary_dict = {env_meth:{} for env_meth in run_dict.keys()}\n",
    "\n",
    "    overall_summary_dict = {k:[] for k in list(summary_key_dict.keys()) + [\"reward_per_episode\"]}\n",
    "\n",
    "    for run_name, run in run_dict.items():\n",
    "\n",
    "        #print(run_name)\n",
    "        for summary_name, key_list in summary_key_dict.items():\n",
    "            run_mean_values = {k.lower():v for k,v in run.items() if \"acc\" in k and \"stderr\" not in k\\\n",
    "                               and  any(sum_key.lower() in k.lower() for sum_key in key_list)}\n",
    "            #run_stderr_values = {k:v for k,v in run.items() if \"stderr\" in k and \"mean\" not in k and any(sum_key in k.lower() for sum_key in key_list)}\n",
    "            if len(run_mean_values) > 0:\n",
    "                run_summary = np.mean(list(run_mean_values.values()))\n",
    "                overall_summary_dict[summary_name].append(run_summary)\n",
    "                run_summary_dict[run_name][summary_name] = run_summary\n",
    "        overall_summary_dict[\"reward_per_episode\"].append(run[\"test_mean_reward_per_episode\"])\n",
    "        run_summary_dict[run_name][\"reward_per_episode\"] = run[\"test_mean_reward_per_episode\"]\n",
    "                #print(\"\\t\",summary_name,run_summary_dict[run_name][summary_name])\n",
    "    overall_summary_dict = {k:np.mean(v) for k,v in overall_summary_dict.items()} \n",
    "    return overall_summary_dict, run_summary_dict #, run_dict, run_info_dict\n",
    "\n",
    "rlag = {k:{} for k in atari_dict.keys()}\n",
    "\n",
    "for algo in [\"a2c\", \"apex\"]:\n",
    "    _, run_summary_dict = get_pretrained_rl_dicts(algo)\n",
    "    for k, v in run_summary_dict.items():\n",
    "        rlag[k.lower()][algo] = (v[\"overall\"]*100,v['reward_per_episode']) \n",
    "    \n",
    "\n",
    "print(\" & \".join([\"game\", \"a2c probe\", \"a2c returns\",\"apex probe\", \"a2c returns\"]), \"\\\\\\\\\")\n",
    "for game, dic in rlag.items():\n",
    "    #print(dic)\n",
    "    if len(dic) > 1:\n",
    "        all_res = list(dic[\"a2c\"]) + list(dic[\"apex\"])\n",
    "        all_res = [\"%.2f\"%(float(n)) for n in all_res]\n",
    "        print(game, \" & \" ,\" & \".join(all_res), \"\\\\\\\\\")\n",
    "    \n",
    "\n",
    "\n",
    "rlov = {}\n",
    "\n",
    "for algo in [\"a2c\", \"apex\"]:\n",
    "    osd, _ = get_pretrained_rl_dicts(algo)\n",
    "    rlov[algo + \"probe avg\"] = osd[\"overall\"]*100\n",
    "    rlov[algo + \"avg return per ep per game\"] = osd['reward_per_episode']\n",
    "\n",
    "\n",
    "a2c0,a2c1 = [\"%8.2f\"%rlov[k] for k in rlov.keys() if \"a2c\" in k]\n",
    "\n",
    "apex0,apex1 = [\"%8.2f\"%rlov[k] for k in rlov.keys() if \"apex\" in k]\n",
    "\n",
    "alla2c_probes = [v[\"a2c\"][0] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "alla2c_returns = [v[\"a2c\"][1] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "a2c_corr = np.corrcoef(alla2c_probes,alla2c_returns)[0][1]\n",
    "\n",
    "allapex_probes =  [v[\"apex\"][0] for v in rlag.values() if len(v) > 0]\n",
    "allapex_returns =  [v[\"apex\"][1] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "apex_corr = np.corrcoef(allapex_probes,allapex_returns)[0][1]\n",
    "\n",
    "print(\" & \".join([\"method\", \"probe_score\", \"avg_returns all games\",\"correlation\"]))\n",
    "print(\" & \".join([\"a2c\",a2c0,a2c1,str(a2c_corr)]))\n",
    "print(\" & \".join([\"apex\",apex0,apex1,str(apex_corr)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
