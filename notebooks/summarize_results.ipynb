{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/evanracah/Dropbox/projects/rl-representation-learning/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.atari_ram_annotations import summary_key_dict, atari_dict, unused_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dicts_in_dict(dic):\n",
    "    rems = []\n",
    "    for k,v in dic.items():\n",
    "        if isinstance(v,dict) or isinstance(v,list):\n",
    "            rems.append(k)\n",
    "    for k in rems:            \n",
    "        if isinstance(dic[k], list):\n",
    "            for i,v in enumerate(dic[k]):\n",
    "                dic[k+\"_\"+str(i)] = v\n",
    "        dic.pop(k)\n",
    "        \n",
    "    return dic\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts_for(method):\n",
    "    rem_games = []\n",
    "    api = wandb.Api()\n",
    "    if method in [\"random_cnn\",\"supervised\"]:\n",
    "        runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": method,\n",
    "                                                 \"config.collect_mode\":\"random_agent\",\n",
    "                                                 \"state\": \"finished\"}))\n",
    "    else:\n",
    "        runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": method,\n",
    "                                                         \"config.collect_mode\":\"random_agent\",\n",
    "                                                         \"config.train_encoder\":True,\n",
    "                                                       \"config.feature_size\":256,\n",
    "                                                         \"state\": \"finished\", \n",
    "                                                        #\"config.patience\":10\n",
    "                                                        }))\n",
    "\n",
    "\n",
    "\n",
    "    runs_info = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\") + \"_\" + run.name :remove_dicts_in_dict(run.config) for run in runs}\n",
    "    summary_metrics = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\") + \"_\" + run.name :run.summary_metrics for run in runs }\n",
    "    summary_metrics = {k:v for k,v in summary_metrics.items() if k.split(\"_\")[0] not in rem_games}\n",
    "    run_summary_dict = {name:{} for name in summary_metrics.keys()}\n",
    "    for run_name, run in summary_metrics.items():\n",
    "        for summary_name, key_list in summary_key_dict.items():\n",
    "            run_mean_values = {k.lower():v for k,v in run.items() if \"acc\" in k and \"stderr\" not in k  and  any(sum_key.lower() in k.lower() for sum_key in key_list)}\n",
    "            #print(run_mean_values)\n",
    "            #run_stderr_values = {k:v for k,v in run.items() if \"stderr\" in k and \"mean\" not in k and any(sum_key in k.lower() for sum_key in key_list)}\n",
    "            if len(run_mean_values) > 0:\n",
    "                run_summary = np.mean(list(run_mean_values.values()))\n",
    "                #overall_summary_dict[summary_name].append(run_summary)\n",
    "                run_summary_dict[run_name][summary_name] = run_summary\n",
    "                #print(\"\\t\",summary_name,run_summary_dict[run_name][summary_name])\n",
    "        run_summary_dict[run_name][\"overall\"] = np.mean(list(run_summary_dict[run_name].values()))\n",
    "                \n",
    "    for game_name in atari_dict.keys():\n",
    "        duplicates = [run_name for run_name in summary_metrics.keys() if game_name in run_name.lower()]\n",
    "        num_duplicates = len(duplicates)\n",
    "        if num_duplicates > 1:\n",
    "            \n",
    "            duplicates_info = [runs_info[run_name] for run_name in duplicates]\n",
    "            print(\"Game {} is in summary {} times as:\".format(game_name, num_duplicates))\n",
    "            print(\"\\t\",duplicates)\n",
    "            print(\"\\tDifferences are: \")\n",
    "            for info in duplicates_info[1:]:\n",
    "                print(\"\\t\\t\",set(duplicates_info[0].items()).symmetric_difference(set(info.items())))\n",
    "            duplicates_time_stamps = [summary_metrics[run_name][\"_timestamp\"] for run_name in duplicates ]\n",
    "            most_recent_index = np.argmax(duplicates_time_stamps)\n",
    "            for i, run_name in enumerate(duplicates):\n",
    "                if i != most_recent_index:\n",
    "                    run_summary_dict.pop(run_name)\n",
    "            \n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "    return run_summary_dict, runs_info, runs \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_summary_dict(run_summary_dict):\n",
    "    all_dups = []\n",
    "    for game_name in atari_dict.keys():       \n",
    "        duplicates = [run_name for run_name in run_summary_dict.keys() if game_name in run_name.lower()]\n",
    "        all_dups.append(duplicates)\n",
    "        num_duplicates = len(duplicates)\n",
    "        if num_duplicates > 1:\n",
    "            print(\"You still have duplicates!\".format(game_name, num_duplicates))\n",
    "            print(\"\\t\",duplicates)\n",
    "            print(\"\")\n",
    "            \n",
    "    overall_summary_dict = {k:[] for k in list(summary_key_dict.keys()) + [\"overall\"]}\n",
    "    for run_name, key_dict in run_summary_dict.items():\n",
    "        for key,value in key_dict.items():\n",
    "            overall_summary_dict[key].append(value)\n",
    "        \n",
    "    overall_summary_dict = {k:np.mean(v) for k,v in overall_summary_dict.items()}\n",
    "\n",
    "\n",
    "    return overall_summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game boxing is in summary 2 times as:\n",
      "\t ['Boxing_zyxbjp4e', 'Boxing_y4lugrs2']\n",
      "\tDifferences are: \n",
      "\t\t {('sequence_length', 10), ('linear', True), ('steps_step', 4), ('sequence_length', 100), ('steps_step', 1), ('steps_end', 99), ('steps_end', 9)}\n",
      "Game pitfall is in summary 2 times as:\n",
      "\t ['Pitfall_i6r8odxn', 'Pitfall_2lwcgebo']\n",
      "\tDifferences are: \n",
      "\t\t {('sequence_length', 10), ('linear', True), ('steps_step', 4), ('sequence_length', 100), ('steps_step', 1), ('steps_end', 99), ('steps_end', 9)}\n",
      "Game pong is in summary 2 times as:\n",
      "\t ['Pong_5xwqtld8', 'Pong_fmc1nnj8']\n",
      "\tDifferences are: \n",
      "\t\t {('sequence_length', 10), ('linear', True), ('steps_step', 4), ('sequence_length', 100), ('steps_step', 1), ('steps_end', 99), ('steps_end', 9)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanracah/miniconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/evanracah/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "run_summary_dict,runs_info, runs = get_dicts_for(\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PitfallNoFrameskip-v4': 0.4999872148036957,\n",
       " 'PongNoFrameskip-v4': 0.5,\n",
       " 'BoxingNoFrameskip-v4': 0.5,\n",
       " 'MontezumaRevengeNoFrameskip-v4': 0.9148263335227966,\n",
       " 'PrivateEyeNoFrameskip-v4': 0.9920879006385804,\n",
       " 'AsteroidsNoFrameskip-v4': 0.828688383102417,\n",
       " 'BerzerkNoFrameskip-v4': 0.8960811495780945,\n",
       " 'BreakoutNoFrameskip-v4': 0.9630773067474364,\n",
       " 'DefenderNoFrameskip-v4': 0.7527104616165161,\n",
       " 'RiverraidNoFrameskip-v4': 0.945261299610138,\n",
       " 'MsPacmanNoFrameskip-v4': 0.9263008236885072}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{run.config[\"env_name\"]: run.summary_metrics[\"train_accuracy\"] for run in runs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PitfallNoFrameskip-v4': 0.4999999701976776,\n",
       " 'PongNoFrameskip-v4': 0.5,\n",
       " 'BoxingNoFrameskip-v4': 0.5,\n",
       " 'MontezumaRevengeNoFrameskip-v4': 0.910187304019928,\n",
       " 'PrivateEyeNoFrameskip-v4': 0.9924938678741456,\n",
       " 'AsteroidsNoFrameskip-v4': 0.517248809337616,\n",
       " 'BerzerkNoFrameskip-v4': 0.840388834476471,\n",
       " 'BreakoutNoFrameskip-v4': 0.9140625,\n",
       " 'DefenderNoFrameskip-v4': 0.4992050528526306,\n",
       " 'RiverraidNoFrameskip-v4': 0.9315848350524902,\n",
       " 'MsPacmanNoFrameskip-v4': 0.9165834784507751}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{run.config[\"env_name\"]: run.summary_metrics[\"val_accuracy\"] for run in runs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small_object_localization': 0.3420865156740226,\n",
       " 'agent_localization': 0.3454388289406672,\n",
       " 'other_localization': 0.4941852057545991,\n",
       " 'score_clock_lives_display': 0.5516124189688962,\n",
       " 'level_room': 0.6836566946918509,\n",
       " 'direction': 0.3821022727272727,\n",
       " 'overall': nan}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_summary_dict(run_summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"random-cnn\", \"vae\", \"cpc\", \"spatial-appo\", \"supervised\"]\n",
    "gbg_dict = {env:{} for env in atari_dict.keys()}\n",
    "\n",
    "overall_dict = {method:{} for method in methods}\n",
    "\n",
    "for method in methods:\n",
    "    overall_summary_dict, run_summary_dict, _ = get_dicts_for(method)\n",
    "    for env, dic in run_summary_dict.items():\n",
    "        if len(dic) > 0:\n",
    "            gbg_dict[env.lower()][method] = dic[\"overall\"]\n",
    "        else:\n",
    "            gbg_dict[env.lower()][method] = \"n/a\"\n",
    "    overall_dict[method] = overall_summary_dict[\"overall\"]\n",
    "\n",
    "print(\" & \".join([\"game\"] + methods), \"\\\\\\\\\")\n",
    "\n",
    "for game, dic in gbg_dict.items():\n",
    "    if game in [\"videopinball\", \"asteroids\"]:\n",
    "        continue\n",
    "    print(\" & \".join([game] + [\"%8.2f\"%(100*dic[k]) if k in dic else \"n/a\" for k in methods ]), \"\\\\\\\\\")\n",
    "\n",
    "\n",
    "print(\" & \".join([\"overall\"] + [\"%8.2f\"%(100*overall_dict[k]) if k in overall_dict else \"n/a\" for k in methods ]), \"\\\\\\\\\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_keys = [\"overall\"]\n",
    "loc_keys = ['localization',\n",
    " 'small_object_localization',\n",
    " 'agent_localization',\n",
    " 'enemy_localization']\n",
    "misc_keys=['relative_position',\n",
    " 'direction',\n",
    " 'score',\n",
    " 'level_room',\n",
    " 'count_display',\n",
    " 'existence',\n",
    " 'speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" & \".join(loc_keys))\n",
    "for method in methods:\n",
    "    overall_summary_dict, run_summary_dict, _ = get_dicts_for(method)\n",
    "\n",
    "\n",
    "    loc_nums = [\"%8.2f\"%(100*overall_summary_dict[k]) for k in loc_keys]\n",
    "    print(method + \" & \",\" & \".join(loc_nums), \"\\\\\\\\\")\n",
    "\n",
    "print(\" & \".join(misc_keys))    \n",
    "for method in methods:\n",
    "    overall_summary_dict, run_summary_dict, _ = get_dicts_for(method)\n",
    "\n",
    "\n",
    "\n",
    "    misc_nums = [\"%8.2f\"%(100*overall_summary_dict[k]) for k in misc_keys]\n",
    "    print(method + \" & \",\" & \".join(misc_nums), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl agent parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_keys = ['overall',\n",
    " 'localization',\n",
    " 'small_object_localization',\n",
    " 'agent_localization',\n",
    " 'enemy_localization']\n",
    "\n",
    "keys = ['overall',\n",
    " 'small_object_localization',\n",
    " 'agent_localization',\n",
    " 'enemy_localization',\"score_lives\", \n",
    " 'count_display','level_room','direction', 'existence']\n",
    "\n",
    "summary_stats = {env:{sk:0 for sk in summary_key_dict.keys()} for env in atari_dict.keys()}\n",
    "\n",
    "for env in atari_dict.keys():\n",
    "    for k in atari_dict[env].keys():\n",
    "        for sk,v in summary_key_dict.items():\n",
    "            if k in v:\n",
    "                summary_stats[env][sk] +=1\n",
    "\n",
    "print(\" & \".join([\"game\"] + list(keys)))\n",
    "\n",
    "for env,v in summary_stats.items():\n",
    "    print( \" & \".join([env] + list(str(v[k]) for k in keys)), \"\\\\\\\\\")\n",
    "\n",
    "\n",
    "\n",
    "def get_pretrained_rl_dicts(algo):\n",
    "    api = wandb.Api()\n",
    "    runs = list(api.runs(\"curl-atari/curl-atari-2\", {\"config.method\": \"pretrained-rl-agent\",\n",
    "                                                     \"config.zoo_algos\":[algo],\n",
    "                                                     \"config.probe_collect_mode\":\"atari_zoo\",\n",
    "                                                     \"state\": \"finished\"}))\n",
    "\n",
    "    runs = [run for run in runs if \"test_mean_reward_per_episode\" in run.summary_metrics.keys()]\n",
    "\n",
    "    run_info_dict = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\")  :run.config for run in runs}\n",
    "    run_dict = {run.config[\"env_name\"].replace(\"NoFrameskip-v4\",\"\")  :run.summary_metrics for run in runs}\n",
    "\n",
    "    run_summary_dict = {env_meth:{} for env_meth in run_dict.keys()}\n",
    "\n",
    "    overall_summary_dict = {k:[] for k in list(summary_key_dict.keys()) + [\"reward_per_episode\"]}\n",
    "\n",
    "    for run_name, run in run_dict.items():\n",
    "\n",
    "        #print(run_name)\n",
    "        for summary_name, key_list in summary_key_dict.items():\n",
    "            run_mean_values = {k.lower():v for k,v in run.items() if \"acc\" in k and \"stderr\" not in k\\\n",
    "                               and  any(sum_key.lower() in k.lower() for sum_key in key_list)}\n",
    "            #run_stderr_values = {k:v for k,v in run.items() if \"stderr\" in k and \"mean\" not in k and any(sum_key in k.lower() for sum_key in key_list)}\n",
    "            if len(run_mean_values) > 0:\n",
    "                run_summary = np.mean(list(run_mean_values.values()))\n",
    "                overall_summary_dict[summary_name].append(run_summary)\n",
    "                run_summary_dict[run_name][summary_name] = run_summary\n",
    "        overall_summary_dict[\"reward_per_episode\"].append(run[\"test_mean_reward_per_episode\"])\n",
    "        run_summary_dict[run_name][\"reward_per_episode\"] = run[\"test_mean_reward_per_episode\"]\n",
    "                #print(\"\\t\",summary_name,run_summary_dict[run_name][summary_name])\n",
    "    overall_summary_dict = {k:np.mean(v) for k,v in overall_summary_dict.items()} \n",
    "    return overall_summary_dict, run_summary_dict #, run_dict, run_info_dict\n",
    "\n",
    "rlag = {k:{} for k in atari_dict.keys()}\n",
    "\n",
    "for algo in [\"a2c\", \"apex\"]:\n",
    "    _, run_summary_dict = get_pretrained_rl_dicts(algo)\n",
    "    for k, v in run_summary_dict.items():\n",
    "        rlag[k.lower()][algo] = (v[\"overall\"]*100,v['reward_per_episode']) \n",
    "    \n",
    "\n",
    "print(\" & \".join([\"game\", \"a2c probe\", \"a2c returns\",\"apex probe\", \"a2c returns\"]), \"\\\\\\\\\")\n",
    "for game, dic in rlag.items():\n",
    "    #print(dic)\n",
    "    if len(dic) > 1:\n",
    "        all_res = list(dic[\"a2c\"]) + list(dic[\"apex\"])\n",
    "        all_res = [\"%.2f\"%(float(n)) for n in all_res]\n",
    "        print(game, \" & \" ,\" & \".join(all_res), \"\\\\\\\\\")\n",
    "    \n",
    "\n",
    "\n",
    "rlov = {}\n",
    "\n",
    "for algo in [\"a2c\", \"apex\"]:\n",
    "    osd, _ = get_pretrained_rl_dicts(algo)\n",
    "    rlov[algo + \"probe avg\"] = osd[\"overall\"]*100\n",
    "    rlov[algo + \"avg return per ep per game\"] = osd['reward_per_episode']\n",
    "\n",
    "\n",
    "a2c0,a2c1 = [\"%8.2f\"%rlov[k] for k in rlov.keys() if \"a2c\" in k]\n",
    "\n",
    "apex0,apex1 = [\"%8.2f\"%rlov[k] for k in rlov.keys() if \"apex\" in k]\n",
    "\n",
    "alla2c_probes = [v[\"a2c\"][0] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "alla2c_returns = [v[\"a2c\"][1] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "a2c_corr = np.corrcoef(alla2c_probes,alla2c_returns)[0][1]\n",
    "\n",
    "allapex_probes =  [v[\"apex\"][0] for v in rlag.values() if len(v) > 0]\n",
    "allapex_returns =  [v[\"apex\"][1] for v in rlag.values() if len(v) > 0]\n",
    "\n",
    "apex_corr = np.corrcoef(allapex_probes,allapex_returns)[0][1]\n",
    "\n",
    "print(\" & \".join([\"method\", \"probe_score\", \"avg_returns all games\",\"correlation\"]))\n",
    "print(\" & \".join([\"a2c\",a2c0,a2c1,str(a2c_corr)]))\n",
    "print(\" & \".join([\"apex\",apex0,apex1,str(apex_corr)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
